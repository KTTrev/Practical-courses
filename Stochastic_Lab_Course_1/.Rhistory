ML.quantile.x<-rep(0,9)
for (i in 1:9){
ML.quantile.x[i]<- quantile(x, 0.5, type = i) #ML.quantile.x stands for Maximum Likelihood for the sample x, using the quantiile function
}
#Another n = 1000 independent realisations of X with mean = 1 and sigma = 1
#and do the same estimations
y<-rlaplace(1000, 1, 1)
ML.quantile.y<-rep(0,9)
for (i in 1:9){
ML.quantile.y[i]<- quantile(y, 0.5, type = i) #ML.quantile.y stands for Maximum Likelihood for the sample y using the quantiile function
}
##(c)
#Write a function that calculates the maximum likelihood estimator for a
#Laplace sample numerically using R function optimise.
Max.logL.num.x <- function(a){
res<-a
for(i in 1:length(res)){
res[i]<- -sum(dlaplace(x, m = a[i], s = 1, log = T))
}
return(res)
}
optimize(Max.logL.num.x, interval = range(x))
#or
Max.logL.num.x <- function(a){
-sum(dlaplace(x, m = a, s = 1, log = T))
}
optimize(Vectorize(Max.logL.num.x), interval = range(x))
#Generate n = 20 and n = 1000 independent realisations of X with mu = 1 and sigma = 1
z<-rlaplace(20, 1, 1)
y<-rlaplace(1000, 1, 1)
#Now we find the MLE of z, first with the previous function, then by using the quantile fucntion
Max.logL.num.z <- function(a){
-sum(dlaplace(z, m = a, s = 1, log = T))
}
optimize(Max.logL.num.z, interval = range(z))
ML.quantile.z<-rep(0,9)
for (i in 1:9){
ML.quantile.z[i]<- quantile(z, 0.5, type = i) #ML.quantile.z stands for Maximum Likelihood for the sample y using the quantiile function
}
#Then, we also find the MLE of y, first with the previous function, then by using the quantile fucntion
Max.logL.num.y <- function(a){
-sum(dlaplace(y, m = a, s = 1, log = T))
}
optimize(Max.logL.num.y, interval = range(y))
ML.quantile.y<-rep(0,9)
for (i in 1:9){
ML.quantile.y[i]<- quantile(y, 0.5, type = i) #ML.quantile.y stands for Maximum Likelihood for the sample y using the quantiile function
}
##(d)
#Let us now study the distribution of the maximum likelihood estimator.
M.20<-rep(0,5000)
for( i in 1:5000){
z<-rlaplace(20, 1, 1)
Max.logL.num.z <- function(a){
-sum(dlaplace(z, m = a, s = 1, log = T))
}
a<- optimize(Max.logL.num.z, interval = range(z))
M.20[i]<-a[[1]]
}
M.1000<-rep(0,5000)
for( i in 1:5000){
y<-rlaplace(1000, 1, 1)
Max.logL.num.y <- function(a){
-sum(dlaplace(y, m = a, s = 1, log = T))
}
a<- optimize(Max.logL.num.y, interval = range(y))
M.1000[i]<-a[[1]]
}
#
data.frame.1000<- as.data.frame(M.1000, stringsAsFactors=FALSE)
p1<-ggplot(data.frame.1000, aes(M.1000))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(data.frame.1000$M.1000), sd = sd(data.frame.1000$M.1000)), color = 'red')+
ggtitle("Histogram: n = 1000")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p2<-ggplot(data.frame.1000, aes(sample = M.1000)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()+
ggtitle("Normal Q-Q Plot \n n = 1000")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
#
data.frame.20<- as.data.frame(M.20, stringsAsFactors=FALSE)
p3<-ggplot(data.frame.20, aes(M.20))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(data.frame.20$M.20), sd = sd(data.frame.20$M.20)), color = 'red')+
ggtitle("Histogram: n = 20")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p4<-ggplot(data.frame.20, aes(sample = M.20)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()+
ggtitle("Normal Q-Q Plot \n n = 20")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
grid.arrange(p1, p2, p3, p4, nrow = 2)
data.frame.20
sd(M.20)
sd(M.1000)
Mean.sd.M.1000<-c(mean(M.1000), sd(M.1000))
Mean.sd.M.20<-c(mean(M.20), sd(M.20))
Mean.sd.M.1000
Mean.sd.M.20
c<-as.data.frame(Mean.sd.M.1000, Mean.sd.M.20)
c<-as.data.frame(Mean.sd.M.1000, Mean.sd.M.20, stringsAsFactors=FALSE)
Mean.sd.M.1000<-c(mean(M.1000), sd(M.1000))
Mean.sd.M.1000
set.seed(12547)
library("ggplot2")
library("rmutil") # contains the function rlaplace
library("gridExtra") #to plot multiple plots in one page
##(b)
#Generate n = 20 independent realisations of X with mean = 1 and sd = 1
x<- rlaplace(20, 1, 1)
#Determine the maximum likelihood estimator of mean based on this sample using R function quantile.
#In order to Experiment with the different 9 types of quantiles available on R, we use the vector MLx
#According to question (a), the maximum likelihood estimator for mean is the median of the sample x
ML.quantile.x<-rep(0,9)
for (i in 1:9){
ML.quantile.x[i]<- quantile(x, 0.5, type = i) #ML.quantile.x stands for Maximum Likelihood for the sample x, using the quantiile function
}
#Another n = 1000 independent realisations of X with mean = 1 and sigma = 1
#and do the same estimations
y<-rlaplace(1000, 1, 1)
ML.quantile.y<-rep(0,9)
for (i in 1:9){
ML.quantile.y[i]<- quantile(y, 0.5, type = i) #ML.quantile.y stands for Maximum Likelihood for the sample y using the quantiile function
}
##(c)
#Write a function that calculates the maximum likelihood estimator for a
#Laplace sample numerically using R function optimise.
Max.logL.num.x <- function(a){
res<-a
for(i in 1:length(res)){
res[i]<- -sum(dlaplace(x, m = a[i], s = 1, log = T))
}
return(res)
}
optimize(Max.logL.num.x, interval = range(x))
#or
Max.logL.num.x <- function(a){
-sum(dlaplace(x, m = a, s = 1, log = T))
}
optimize(Vectorize(Max.logL.num.x), interval = range(x))
#Generate n = 20 and n = 1000 independent realisations of X with mu = 1 and sigma = 1
z<-rlaplace(20, 1, 1)
y<-rlaplace(1000, 1, 1)
#Now we find the MLE of z, first with the previous function, then by using the quantile fucntion
Max.logL.num.z <- function(a){
-sum(dlaplace(z, m = a, s = 1, log = T))
}
optimize(Max.logL.num.z, interval = range(z))
ML.quantile.z<-rep(0,9)
for (i in 1:9){
ML.quantile.z[i]<- quantile(z, 0.5, type = i) #ML.quantile.z stands for Maximum Likelihood for the sample y using the quantiile function
}
#Then, we also find the MLE of y, first with the previous function, then by using the quantile fucntion
Max.logL.num.y <- function(a){
-sum(dlaplace(y, m = a, s = 1, log = T))
}
optimize(Max.logL.num.y, interval = range(y))
ML.quantile.y<-rep(0,9)
for (i in 1:9){
ML.quantile.y[i]<- quantile(y, 0.5, type = i) #ML.quantile.y stands for Maximum Likelihood for the sample y using the quantiile function
}
##(d)
#Let us now study the distribution of the maximum likelihood estimator.
M.20<-rep(0,5000)
for( i in 1:5000){
z<-rlaplace(20, 1, 1)
Max.logL.num.z <- function(a){
-sum(dlaplace(z, m = a, s = 1, log = T))
}
a<- optimize(Max.logL.num.z, interval = range(z))
M.20[i]<-a[[1]]
}
M.1000<-rep(0,5000)
for( i in 1:5000){
y<-rlaplace(1000, 1, 1)
Max.logL.num.y <- function(a){
-sum(dlaplace(y, m = a, s = 1, log = T))
}
a<- optimize(Max.logL.num.y, interval = range(y))
M.1000[i]<-a[[1]]
}
#
data.frame.1000<- as.data.frame(M.1000, stringsAsFactors=FALSE)
p1<-ggplot(data.frame.1000, aes(M.1000))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(data.frame.1000$M.1000), sd = sd(data.frame.1000$M.1000)), color = 'red')+
ggtitle("Histogram: n = 1000")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p2<-ggplot(data.frame.1000, aes(sample = M.1000)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()+
ggtitle("Normal Q-Q Plot \n n = 1000")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
#
data.frame.20<- as.data.frame(M.20, stringsAsFactors=FALSE)
p3<-ggplot(data.frame.20, aes(M.20))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(data.frame.20$M.20), sd = sd(data.frame.20$M.20)), color = 'red')+
ggtitle("Histogram: n = 20")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p4<-ggplot(data.frame.20, aes(sample = M.20)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()+
ggtitle("Normal Q-Q Plot \n n = 20")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
grid.arrange(p1, p2, p3, p4, nrow = 2)
#Mean and sd of both samples
Mean.sd.M.1000<-c(mean(M.1000), sd(M.1000))
Mean.sd.M.20<-c(mean(M.20), sd(M.20))
Mean.sd.M.1000
Mean.sd.M.20
library("dplyr")
#data frame that contains the data
#This can be done by creating a matrix, a list, and then using the function as.data.frame
M<- cbind(c(497, 221, 212, 503, 1841), c(62, 12, 20, 102, 305))
N<- cbind(c(694, 4840, 383, 320, 201), c(117, 415, 65, 129, 61))
#renaming rows and columns of M and N
rownames(M)<- c('Los Angeles', 'Phoenix', 'San Diego', 'San Francisco', 'Seattle')
colnames(M)<- c('On time', 'Delayed')
rownames(N)<- c('Los Angeles', 'Phoenix', 'San Diego', 'San Francisco', 'Seattle')
colnames(N)<- c('On time', 'Delayed')
#creating list
L<- list("Alaska Airlines" = M, "America West" = N)
#Finally the dataframe
df <- data.frame(L)
df_city_delayed<- select(df, c(Alaska.Airlines.Delayed, America.West.Delayed))
#(a)
#Chi-squared test for homogeneity
chisq.test(df_city_delayed)
#(b)
#Test with an appropriate test if the delay is independent on the airline.
#I think we can use a Fischer exact test, but do not really know why. ????
fisher.test(df_city_delayed) #why it does not work????
#(c)
#For each airline use the appropriate test to test if the delay probability equals to 0.14 .
#In each airline, we can consider the number of delays as success, and on time as failures.
#Therefore, at Alaska.Airlines, the number of success
#is nothing but sum(df$Alaska.Airlines.Delayed), and the number of failures is sum(df$Alaska.Airlines.On.time)
#Alaska.Airlines
x<-sum(df$Alaska.Airlines.Delayed)
p<-0.14
n<-sum(df$Alaska.Airlines.Delayed) + sum(df$Alaska.Airlines.On.time)
binom.test(x, n, p)
df_city_delayed
#Chi-squared test for homogeneity
chisq.test(df_city_delayed)
m <- matrix(1:20, 4)
m
freq<-df_city_delayed
freq
freq<-df_city_delayed
Total.r<-c(sum(freq$Alaska.Airlines.Delayed), sum(freq$America.West.Delayed))
Total.r
freq<-rbind(df_city_delayed, Total.r)
freq
freq<-row.names("Los Angeles", "Phoenix", "San Diego", "San Francisco", "Seattle", "Total.r")
freq<-rownames("Los Angeles", "Phoenix", "San Diego", "San Francisco", "Seattle", "Total.r")
?rownames
?row.names
freq<-row.names(Los Angeles, Phoenix, San Diego, San Francisco, Seattle, Total.r)
freq
Total.c<-freq$Alaska.Airlines.Delayed + freq$America.West.Delayed
Total.c
freq<-cbind(freq, Total.c)
freq
freq[1,1]
freq[1,]
freq[,1]
freq
freq[6,1]
freq[6/6]
freq[6,6]
freq[6,2]
freq[2,6]
freq
freq[6,3]
a<-(freq[6,1]/freq[6,3])*(freq$Alaska.Airlines.Delayed)
a
a<-(freq[6,1]/freq[6,3])*(Total.c)
a
freq
freq[6,2]
b<-(freq[6,2]/freq[6,3])*(Total.c)
b
b<-NULL
b
b[6]<-NULL
b<-(freq[6,2]/freq[6,3])*(Total.c)
b[6]<-NULL
b[1]
freq
a<-(freq[6,1]/freq[6,3])*(Total.c)
head(a, -1)
b<-(freq[6,2]/freq[6,3])*(Total.c)
head(b, -1)
df_city_delayed
D<-cbind(a, b)
D
a<-(freq[6,1]/freq[6,3])*(Total.c)
a
head(a, -1)   #to remove the last element
a<-(freq[6,1]/freq[6,3])*(Total.c)
a<-head(a, -1)   #to remove the last element
b<-(freq[6,2]/freq[6,3])*(Total.c)
b<-head(b, -1)
D<-cbind(a, b)
D
df_city_delayed
l<-(df_city_delayed$Alaska.Airlines.Delayed - a)**2
l
l<-(df_city_delayed$America.West.Delayed - b)**2
l
k/a
k
k<-(df_city_delayed$Alaska.Airlines.Delayed - a)**2
l<-(df_city_delayed$America.West.Delayed - b)**2
k
k/a
l/b
test.statistics<-(k/a)+(l/b)
test.statistics
test.statistics<-sum(k/a)+sum(l/b)
test.statistics
library("dplyr")
#data frame that contains the data
#This can be done by creating a matrix, a list, and then using the function as.data.frame
M<- cbind(c(497, 221, 212, 503, 1841), c(62, 12, 20, 102, 305))
N<- cbind(c(694, 4840, 383, 320, 201), c(117, 415, 65, 129, 61))
#renaming rows and columns of M and N
rownames(M)<- c('Los Angeles', 'Phoenix', 'San Diego', 'San Francisco', 'Seattle')
colnames(M)<- c('On time', 'Delayed')
rownames(N)<- c('Los Angeles', 'Phoenix', 'San Diego', 'San Francisco', 'Seattle')
colnames(N)<- c('On time', 'Delayed')
#creating list
L<- list("Alaska Airlines" = M, "America West" = N)
#Finally the dataframe
df <- data.frame(L)
df_city_delayed<- select(df, c(Alaska.Airlines.Delayed, America.West.Delayed))
#(a)
#Chi-squared test for independence with the test statistic
freq<-df_city_delayed
Total.r<-c(sum(freq$Alaska.Airlines.Delayed), sum(freq$America.West.Delayed))
freq<-rbind(df_city_delayed, Total.r)
Total.c<-freq$Alaska.Airlines.Delayed + freq$America.West.Delayed
freq<-cbind(freq, Total.c)
#In the following lines, we calculate the observed freequencies
a<-(freq[6,1]/freq[6,3])*(Total.c)
a<-head(a, -1)   #to remove the last element
b<-(freq[6,2]/freq[6,3])*(Total.c)
b<-head(b, -1)
k<-(df_city_delayed$Alaska.Airlines.Delayed - a)**2
l<-(df_city_delayed$America.West.Delayed - b)**2
test.statistics<-sum(k/a)+sum(l/b)
#Chi-squared test for independence with the r command chisq.test
chisq.test(df_city_delayed)
#(b)
#Test with an appropriate test if the delay is independent on the airline.
#I think we can use a Fischer exact test, but do not really know why. ????
fisher.test(df_city_delayed) #why it does not work????
#(c)
#For each airline use the appropriate test to test if the delay probability equals to 0.14 .
#In each airline, we can consider the number of delays as success, and on time as failures.
#Therefore, at Alaska.Airlines, the number of success
#is nothing but sum(df$Alaska.Airlines.Delayed), and the number of failures is sum(df$Alaska.Airlines.On.time)
#Alaska.Airlines
x<-sum(df$Alaska.Airlines.Delayed)
p<-0.14
n<-sum(df$Alaska.Airlines.Delayed) + sum(df$Alaska.Airlines.On.time)
binom.test(x, n, p)
library(ggfortify)
#(a)
#Create a reduced dataset discarding the species
df<-iris
df$Species<-NULL
#principal componets
pca_cov = prcomp(df, scale=FALSE)
summary(pca_cov)
pca_cov
scores(pca_cov)
pca_cov$loadings
pca_cov = prcomp(df, scale=FALSE, scores=T, cor=T)
pca_cov = prcomp(df, scale=FALSE, scores=T, cor=T)
?prcomp
pca_cov = prcomp(df,  scores=T, cor=T)
pca_cov$x
pca_cov$rotation
pca_cov
setwd("~/Desktop/MScMaths/Summer2018/Stochastic_Lab_Course_1/CodeAndData")
library("dplyr")
library("ggplot2")
library("gridExtra") #to plot multiple plots in one page
##(a)
#Read the data into R
elections<- read.csv("Presidential_race_2016.csv")
#add the variable vote
elections$vote<-ifelse(elections$Percent.Clinton > elections$Percent.Trump, 1, 0)
#Divide variable Diversity.Index into two groups: the one that corresponds
#to 1 in vote and another one that corresponds to 0 in vote.
#We would like to compare diversity indices in both groups.
#Check if the diversity index in each group is normally distributed or not, with different graphs
elections_diversity_1<- select(filter(elections, vote == 1), Diversity.Index, Percent.Clinton, Percent.Trump)
elections_diversity_0<- select(filter(elections, vote == 0), Diversity.Index, Percent.Clinton, Percent.Trump)
# for elections_diversity_1: histogram and QQ-plot. The red line on the histogram indicates the normal
#distribution
p1<-ggplot(elections_diversity_1, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections_diversity_1$Diversity.Index), sd = sd(elections_diversity_1$Diversity.Index)), color = 'red')+
ggtitle("Histogram \n Diversity.Index, vote = 1")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p1
p2<-ggplot(elections_diversity_1, aes(sample = Diversity.Index)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()+
ggtitle("Normal Q-Q Plot \n Diversity.Index, vote = 1")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p2
setwd("~/Desktop/MScMaths/Summer2018/Stochastic_Lab_Course_1/CodeAndData")
library("dplyr")
library("ggplot2")
library("gridExtra") #to plot multiple plots in one page
##(a)
#Read the data into R
elections<- read.csv("Presidential_race_2016.csv")
#add the variable vote
elections$vote<-ifelse(elections$Percent.Clinton > elections$Percent.Trump, 1, 0)
#Divide variable Diversity.Index into two groups: the one that corresponds
#to 1 in vote and another one that corresponds to 0 in vote.
#We would like to compare diversity indices in both groups.
#Check if the diversity index in each group is normally distributed or not, with different graphs
elections_diversity_1<- select(filter(elections, vote == 1), Diversity.Index, Percent.Clinton, Percent.Trump)
elections_diversity_0<- select(filter(elections, vote == 0), Diversity.Index, Percent.Clinton, Percent.Trump)
# for elections_diversity_1: histogram and QQ-plot. The red line on the histogram indicates the normal
#distribution
p1<-ggplot(elections_diversity_1, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections_diversity_1$Diversity.Index), sd = sd(elections_diversity_1$Diversity.Index)), color = 'red')+
ggtitle("Histogram \n Diversity.Index, vote = 1")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p2<-ggplot(elections_diversity_1, aes(sample = Diversity.Index)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()+
ggtitle("Normal Q-Q Plot \n Diversity.Index, vote = 1")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
# for elections_diversity_0: histogram and QQ-plot. The red line on the higram indicates the normal
#distribution
p3<-ggplot(elections_diversity_0, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections_diversity_0$Diversity.Index), sd = sd(elections_diversity_0$Diversity.Index)), color = 'red')+
ggtitle("Histogram \n Diversity.Index, vote = 0")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
p4<-ggplot(elections_diversity_0, aes(sample = Diversity.Index)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()+
ggtitle("Normal Q-Q Plot \n Diversity.Index, vote = 0")+
theme(plot.title = element_text(hjust = 0.5)) #Title to the centre
grid.arrange(p1, p2, p3, p4, nrow = 2)
#(b)
#testing the independence between the two groups
chisq.test(c(sum(elections_diversity_1$Diversity.Index), sum(elections_diversity_0$Diversity.Index)))
#t-test: According to question (a), since no normality has been assumed,
#one rather tests
#H0 : median(elections_diversity_1) = median(elections_diversity_0) vs
#H1 : median(elections_diversity_1) != median(elections_diversity_0)
t.test(elections_diversity_1$Diversity.Index, elections_diversity_0$Diversity.Index)
#Wilcoxon test for the same hypothesis with the same significance level.
wilcox.test(elections_diversity_1$Diversity.Index, elections_diversity_0$Diversity.Index, mu = 0, conf.int = T)
#(c)
r1<-ggplot(elections, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections$Diversity.Index), sd = sd(elections$Diversity.Index)), color = 'red')+
r2<-ggplot(elections, aes(sample = Diversity.Index)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()
grid.arrange(r1, r2, nrow = 1)
r2
r1
ggplot(elections, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections$Diversity.Index), sd = sd(elections$Diversity.Index)), color = 'red')+
:
r1<-ggplot(elections, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections$Diversity.Index), sd = sd(elections$Diversity.Index)), color = 'red')
r1
r2<-ggplot(elections, aes(sample = Diversity.Index)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()
r2
r1<-ggplot(elections, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections$Diversity.Index), sd = sd(elections$Diversity.Index)), color = 'red')
r2<-ggplot(elections, aes(sample = Diversity.Index)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()
grid.arrange(r1, r2, nrow = 1)
r1<-ggplot(elections, aes(Diversity.Index))+
geom_histogram(aes(y = ..density..), color = 'white')+
stat_function(fun = dnorm, args = list(mean = mean(elections$Diversity.Index), sd = sd(elections$Diversity.Index)), color = 'red')
r2<-ggplot(elections, aes(sample = Diversity.Index)) +
stat_qq(distribution = stats::qnorm) +
stat_qq_line()
grid.arrange(r1, r2, nrow = 2)
t.test(elections$Diversity.Index, elections$Diversity.Index)
?t.test
t.test(elections$Diversity.Index, elections$Diversity.Index, mu = 50)
t.test(elections$Diversity.Index, elections$Diversity.Index, mu = 50)
wilcox.test(elections$Diversity.Index, elections$Diversity.Index, mu = 50, conf.int = T)
t.test(elections$Diversity.Index, elections$Diversity.Index, mu = 50)
wilcox.test(elections$Diversity.Index, elections$Diversity.Index, mu = 50, conf.int = T)
t.test(elections$Diversity.Index, elections$Diversity.Index, mu = 50)
wilcox.test(elections$Diversity.Index, elections$Diversity.Index, mu = 50, conf.int = T)
